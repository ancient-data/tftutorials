{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/tf.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/ninologo.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/dans.png\" width=\"128\"/>\n",
    "\n",
    "---\n",
    "\n",
    "To get started: consult [start](start.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "# Part of Speech tagging\n",
    "\n",
    "## Team\n",
    "\n",
    "name | discipline | stage | affiliation\n",
    "--- | --- | --- | ---\n",
    "Alba de Ridder | Assyriology | master student | NINO, Leiden\n",
    "Martijn Kokken | Assyriology | master student | NINO, Leiden\n",
    "Dirk Roorda | Computer Science | researcher | DANS, Den Haag\n",
    "Cale Johnson | Assyriology | researcher and lecturer | Univ Birmingham\n",
    "Caroline Waerzeggers | Assyriology | director | NINO, Leiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOPHON = dict(\n",
    "  acronym='ABB-pos',\n",
    "  corpus='Old Babylonian Letter Corpus (ABB)',\n",
    "  dataset='oldbabylonian',\n",
    "  compiler='Dirk Roorda',\n",
    "  editors='Alba de Ridder, Martijn Kokken',\n",
    "  initiators='Cale Johnson, Caroline Waerzeggers',\n",
    "  institute='NINO, DANS',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status\n",
    "\n",
    "* 2019-06-06 Personal pronouns added\n",
    "* 2019-06-05 Dirk has reorganised the messy code after the sprint into a repeatable and documented workflow.\n",
    "  The workflow covers special cases, prepositions, and nouns, not yet the extra insights of the sprint.\n",
    "* 2019-06-03/04 Martijn, Alba and Dirk do a two-day sprint to follow-up on heuristics supplied by Cale Johnson.\n",
    "  Martijn and Alba provide extra insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We collect and execute ideas to tag all word occurrences with a part-of-speech, such as `noun`, `prep`, `verb`.\n",
    "\n",
    "In the end, we intend to provide extra features to the Old Babylonian corpus, as a standard module that will be always loaded\n",
    "alongside the corpus.\n",
    "\n",
    "This notebook will produce some word-level features:\n",
    "\n",
    "* `pos`: main category of the word: `noun`, `verb`, `prep`, `pcl` (particle)\n",
    "* `subpos`: secondary category of the word: `rel` (relation), `neg` (negation)\n",
    "\n",
    "But in the meanwhile, it is work in progress, and during the work we collect candidate assignments in sets, which we save to disk.\n",
    "\n",
    "These sets correspond to `noun`, `prep`, `nonprep` words as far as we have tagged them in the current state of the workflow.\n",
    "\n",
    "The sets are all saved in a file `sets.tfx`, both next to this notebook (so that you can get it through GitHub), as in a shared\n",
    "Dropbox folder `obb`, so that the Akkadian specialists (Alba de Ridder, Martijn Kokken, Cale Johnson) have instant access to them and\n",
    "can test them in their TF-browser.\n",
    "\n",
    "See [pos](pos.ipynb) to see how you can make use of these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n",
    "\n",
    "## Overview\n",
    "\n",
    "We perform the following steps in that order:\n",
    "\n",
    "### Known words\n",
    "We identify a bunch of words in closed categories that tend to interfere with noun/verb detection.\n",
    "After identification, we exclude them from all subsequent pattern detection.\n",
    "\n",
    "### Prepositions\n",
    "We detect a few prepositions, especially those that (nearly) always preceed a noun.\n",
    "\n",
    "### Nouns\n",
    "We use several markers to detect nouns:\n",
    "\n",
    "* determinatives\n",
    "* prepositions\n",
    "* Sumerian logograms\n",
    "* numerals\n",
    "\n",
    "We collect the marked occurrences and then look up the unmarked occurrences of the same words.\n",
    "In this way we extend the detection of nouns considerably.\n",
    "\n",
    "We have to deal with one big complication, though: **unkowns**.\n",
    "If we have marked word occurrences with unknown signs in them, we cannot be confident that unmarked occurrences\n",
    "of the same thing are really occurrences of the same underlying word.\n",
    "\n",
    "So, if we transfer categorizations from marked occurrences to unmarked occurrences, we only do so if\n",
    "the word in question does not have unknowns.\n",
    "\n",
    "We save a lot of intermediate sets: for each step we save the nouns that result from that step:\n",
    "\n",
    "These sets may overlap.\n",
    "\n",
    "We also save subsets of these sets, namely the occurrences that are positively marked, and\n",
    "the occurrences that lack marking and have been inferred.\n",
    "These marked and unmarked subsets of each step are disjoint. \n",
    "\n",
    "whole step | marked | unmarked\n",
    "--- | --- | ---\n",
    "`noundet` | `nounMdet` | `nounUdet`\n",
    "`nounprep` | `nounMprep` | `nounUprep`\n",
    "`nounlogo` | `nounMlogo` | `nounUlogo`\n",
    "`nounnum` | `nounMnum` | `nounUnum`\n",
    "\n",
    "**Note on determinatives**\n",
    "\n",
    "Determinative and phonetic complements are signs marked in ATF by being inside `{ }`, and in TF by having `det=1`.\n",
    "From now on, we will abbreviate it: a **det** is a determinative or a phonetic complement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the engines\n",
    "\n",
    "We load the Python modules we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "\n",
    "from tf.app import use\n",
    "\n",
    "from pos import PosTag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus and obtain a handle to it: `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = use('oldbabylonian:local', checkout='local', hoist=globals(), silent='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the detection machinery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT = PosTag(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step: Inventory\n",
    "\n",
    "We collect all the words and their occurrences and sift through determinatives and numerals.\n",
    "\n",
    "We make a dictionary of words and their occurrences.\n",
    "When we compute the word form, we pick the basic info of a sign, not the full ATF-representation with flags and brackets.\n",
    "\n",
    "We also store the form without the *dets* that are present in the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step: Known words\n",
    "\n",
    "The case specification is a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = '''\n",
    "  la + u2-ul + u2-la = pcl, neg\n",
    "  sza = pcl, rel\n",
    "  u3 + u2-lu + u2 = pcl, conj\n",
    "  lu = pcl\n",
    "  an-nu-um + an-ni-im + an-nu-u2 = prn, dem\n",
    "  i-na-an-na + a-nu-um-ma = adv, tmp\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be read as follows:\n",
    "\n",
    "Each line specifies a bunch of words, separated by `+` on the left hand side of the `=`;\n",
    "the right hand side specifies the categories those words receive, separated by `,`.\n",
    "\n",
    "The first category is the `pos`, (main part-of-speech),\n",
    "the second category is the `subpos` (sub category within the main part-of-speech).\n",
    "\n",
    "We use abbreviated forms, because users of this dataset will have to type them quite often.\n",
    "\n",
    "### Categories\n",
    "\n",
    "category | subcategory | meaning\n",
    "--- | --- | ---\n",
    "`pcl` | &nbsp; | particle (unspecified)\n",
    "`pcl` | `neg` | negative particle\n",
    "`pcl` | `rel` | relative particle\n",
    "`pcl` | `conj` | conjunction\n",
    "`prn` | `dem` | demonstrative pronoun\n",
    "`adv` | `tmp` | temporal adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT.doKnownCases(cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step: Pronouns - personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prnPrs = '''\n",
    "nom:\n",
    "  1csg:\n",
    "    - a-na-ku\n",
    "    - a-na-ku-ma\n",
    "    - a-na-ku-u2\n",
    "    - a-na-ku-u2-ma\n",
    "    - a-na-ku-ma-mi\n",
    "  2msg:\n",
    "    - at-ta\n",
    "    - at-ta-ma\n",
    "    - at-ta-a\n",
    "    - at-ta-a-ma\n",
    "  2fsg:\n",
    "    - at-ti\n",
    "    - at-ti-ma\n",
    "    - at-ti-i-ma\n",
    "  3msg:\n",
    "    - szu-u2\n",
    "    - szu-u2-ma\n",
    "  3fsg:\n",
    "    - szi-i\n",
    "    - szi-i-ma\n",
    "  1mpl:\n",
    "    - ni-nu\n",
    "    - ni-i-ni\n",
    "  2mpl:\n",
    "    - at-tu-nu\n",
    "    - at-tu-nu-ma\n",
    "    - at-tu-nu-u2\n",
    "    - at-tu-u2-nu\n",
    "    - at-tu-u2-nu-ma\n",
    "  2fpl:\n",
    "    - at-ti-na-ma\n",
    "  3mpl:\n",
    "    - szu-nu\n",
    "    - szu-nu-ma\n",
    "    - szu-nu-mi\n",
    "    - szu-nu-u2\n",
    "  3fpl:\n",
    "    - szi-na\n",
    "\n",
    "obl:\n",
    "  1csg:\n",
    "    - ia-ti\n",
    "    - ia-ti-i-ma\n",
    "    - ia-a-ti\n",
    "  2msg:\n",
    "    - ka-ta\n",
    "    - ka-ta-a-ma\n",
    "    - ka-a-ti\n",
    "    - ka-ti:\n",
    "        - P510880 reverse:8\n",
    "        - P306656 obverse:8\n",
    "    - ka-ti-i:\n",
    "        - P292855 obverse:4\n",
    "        - P292983 obverse:4\n",
    "  2fsg:\n",
    "    - ka-ti\n",
    "  3csg:\n",
    "    - szu-a-ti\n",
    "    - szu-a-tu\n",
    "    - sza-a-ti\n",
    "    - sza-a-tu\n",
    "    - szi-a-ti\n",
    "  1cpl:\n",
    "    - ni-a-ti\n",
    "  2mpl:\n",
    "    - ku-nu-ti\n",
    "  2fpl:\n",
    "    - /\n",
    "  3mpl:\n",
    "    - szu-nu-ti\n",
    "  3fpl:\n",
    "    - szi-na-ti\n",
    "\n",
    "dat:\n",
    "  1csg:\n",
    "    - ia-szi\n",
    "    - ia-szi-im\n",
    "    - ia-a-szi\n",
    "    - ia-a-szi-im\n",
    "  2csg:\n",
    "    - ka-szi-im\n",
    "    - ka-szi-im-ma\n",
    "    - ka-a-szum\n",
    "  3msg:\n",
    "    - szu-a-szi-im\n",
    "  1cpl:\n",
    "    - /\n",
    "  2mpl:\n",
    "    - ku-nu-szi-im\n",
    "  2fpl:\n",
    "    - /\n",
    "  3mpl:\n",
    "    - szu-nu-szi-im-ma\n",
    "  3fpl:\n",
    "    - /\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT.doPrnPrs(prnPrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step: Prepositions\n",
    "\n",
    "The following prepositions are known to precede nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preps = '''\n",
    "  i-na\n",
    "  a-na\n",
    "  e-li\n",
    "  isz-tu\n",
    "  it-ti\n",
    "  ar-ki\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT.doPreps(preps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have made a set of all non-prepositions, i.e. all word occurrences not of one of these prepositions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step: Nouns\n",
    "\n",
    "### pass: Determiners\n",
    "\n",
    "We take all words that have a *det*.\n",
    "\n",
    "We collect the *markedData* for this step: all words that have a *det* inside.\n",
    "\n",
    "The *unmarkedData* for this step are the occurrences of the stripped forms of the marked words, i.e.\n",
    "the forms with the *det*s removed.\n",
    "But only if those forms do not have an unknown in them., i.e. a `x`, `n`, or `...`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pass: Prepositions\n",
    "\n",
    "Words after the given set of prepositions are usually nouns.\n",
    "However, sometimes there are multiple prepositions in a row.\n",
    "We take care that we do not mark those second prepostions as nouns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pass: Sumerian logograms\n",
    "\n",
    "Any word that has one or more Sumerian logograms in it, will be marked as noun.\n",
    "\n",
    "Sumerian logograms are defined as signs within the scope of an enclosing `_ _` pair.\n",
    "\n",
    "In TF such signs are characterized by having `langalt=1`.\n",
    "\n",
    "The unmarked data are the occurrences of the same words, but where none of the signs have `langalt=1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pass: Numerals\n",
    "\n",
    "Numerals are individual signs, but they can be part of words.\n",
    "In those cases, we call the whole word a numeral.\n",
    "\n",
    "We consider the category of numeral words as a subcategory of the nouns.\n",
    "\n",
    "Note that there are also unknown numerals: those with reading `n`.\n",
    "\n",
    "A numeral is always marked, there is no concept of unmarked occurrences of numerals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT.doNouns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "We specify the metadata that we want to include into our new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData = {\n",
    "  '': COLOPHON,\n",
    "  'pos': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'primary part-of-speech category on full words',\n",
    "  },\n",
    "  'subpos': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'secondary category within part-of-speech on full words',\n",
    "  },\n",
    "  'cs': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'grammatical case: nom, acc, acg, gen, dat',\n",
    "  },\n",
    "  'ps': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'grammatical person: 1, 2, 3',\n",
    "  },\n",
    "  'gn': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'grammatical gender: m, f, c',\n",
    "  },\n",
    "  'nu': {\n",
    "    'valueType': 'str',\n",
    "    'description': 'grammatical number: sg, du, pl',\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell saves the features to disk, and the sets as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT.export(metaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "next: [pos](pos.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "full posTag and pos notebooks on\n",
    "[annotation/tutorials/oldbabylonian/cookbook](https://nbviewer.jupyter.org/github/annotation/tutorials/blob/master/oldbabylonian/cookbook)\n",
    "\n",
    "full tutorial on\n",
    "[annotation/tutorials/oldbabylonian](https://nbviewer.jupyter.org/github/annotation/tutorials/blob/master/oldbabylonian)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
